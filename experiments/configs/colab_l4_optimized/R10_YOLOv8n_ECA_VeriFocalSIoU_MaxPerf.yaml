# R10: YOLOv8n + ECA + VeriFocal+SIoU - Maximum Performance
# ============================================================================
# Target: 96.0% mAP@0.5 (ECA attention boost on advanced loss)
# Strategy: Channel attention + quality-aware classification + shape-aware IoU

experiment:
  name: "R10_YOLOv8n_ECA_VeriFocalSIoU_MaxPerf_640px"
  type: "attention_enhanced_performance"
  mode: "train"
  description: "YOLOv8n with ECA attention + VeriFocal+SIoU optimized for maximum performance"
  tags:
    - "research_attention_enhancement"
    - "yolov8n"
    - "eca_attention"
    - "verifocal_siou_loss"
    - "max_performance"
    - "phase_3"

model:
  type: "yolov8n"
  config_path: "ultralytics/cfg/models/v8/yolov8n-eca-final.yaml"
  pretrained: true
  attention_mechanism: "eca"

data:
  num_classes: 6

training:
  dataset:
    path: "experiments/configs/datasets/hripcb_data.yaml"
  epochs: 120                           # Optimized for performance vs time
  batch: 64                             # Conservative for attention stability
  imgsz: 640
  device: "0"
  workers: 8                            # Colab CPU optimized
  seed: 42
  
  # Attention-optimized hyperparameters for maximum performance
  optimizer: "AdamW"
  lr0: 0.0008                           # Conservative for attention stability
  lrf: 0.002                            # Lower final LR for attention fine-tuning
  weight_decay: 0.0001                  # Lower for better generalization
  momentum: 0.95                        # Higher momentum for smoother convergence
  warmup_epochs: 20.0                   # Extended warmup for attention adaptation
  patience: 40                          # Balanced for convergence
  
  # Speed optimizations (non-performance affecting)
  save_period: 20
  validate: true
  cache: true                           # Dataset caching for speed
  amp: true                            # Mixed precision (2x speed, no perf loss)
  project: "experiments/pcb-defect-research-maxperf"
  
  # VeriFocal+SIoU optimized for ECA attention
  loss:
    type: "verifocal_siou"
    box_weight: 8.5                     # Balanced for SIoU + ECA
    cls_weight: 0.8                     # Enhanced for VeriFocal + attention
    dfl_weight: 1.9                     # Enhanced DFL
    
  # Balanced augmentation for attention stability
  augmentation:
    mosaic: 0.8                         # Reduced but still significant
    mixup: 0.1                          # Moderate mixup
    copy_paste: 0.2                     # Conservative copy-paste
    hsv_h: 0.01                         # Minimal color variations
    hsv_s: 0.4                          # Moderate saturation
    hsv_v: 0.2                          # Conservative brightness
    degrees: 0.0
    translate: 0.05                     # Minimal translation
    scale: 0.3                          # Conservative scaling
    shear: 0.0
    perspective: 0.0
    flipud: 0.0
    fliplr: 0.4                         # Moderate horizontal flip

validation:
  batch: 64                             # Match training batch for consistency
  imgsz: 640
  conf_threshold: 0.001
  iou_threshold: 0.6
  max_detections: 300
  split: "val"

wandb:
  project: "pcb-defect-research-maxperf"
  save_code: true
  dir: "./wandb_logs"

metadata:
  dataset_name: "HRIPCB"
  hardware: "Colab L4 GPU (22GB)"
  target_performance: "96.0% mAP@0.5"
  estimated_time: "2.5 hours"
  notes: "ECA channel attention + VeriFocal quality-aware classification + SIoU shape-aware localization"