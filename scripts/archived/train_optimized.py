#!/usr/bin/env python3
"""
Optimized YOLOv8n Training Script for HRIPCB Dataset
===================================================

Research-validated hyperparameters for small, linear defect detection.
Pre-configured for ablation study between SIoU and EIoU losses.

Dataset: HRIPCB (class-balanced, small linear defects)
Recommended: Use with SIoU or EIoU loss modifications in ultralytics/utils/loss.py
"""

import os
import torch
from pathlib import Path
from ultralytics import YOLO

def train_hripcb_optimized(loss_function="siou"):
    """
    Train YOLOv8n on HRIPCB dataset with research-validated hyperparameters.
    
    Args:
        loss_function (str): Loss function name for experiment naming ("siou", "eiou", "ciou")
    
    Hyperparameters optimized for:
    - Small, linear defects (benefits from EIoU/SIoU)
    - Class-balanced dataset (standard BCE classification loss)
    - PCB defect detection patterns
    - Fast training with 15GB GPU utilization
    """
    
    print("üöÄ YOLOv8n Optimized Training for HRIPCB Dataset")
    print("=" * 60)
    print("üéØ Target: Small, linear PCB defects")
    print("üìä Dataset: Class-balanced HRIPCB") 
    print(f"üîß Loss: {loss_function.upper()} (modify loss.py as instructed)")
    print("üíæ Experiment: yolov8n_hripcb_{}_loss_optimized".format(loss_function))
    print("=" * 60)
    
    # Verify CUDA availability
    if not torch.cuda.is_available():
        print("‚ö†Ô∏è  WARNING: CUDA not available, training will be slow on CPU")
    else:
        print(f"üéØ GPU: {torch.cuda.get_device_name(0)}")
    
    # Initialize YOLOv8n model
    print("üì¶ Loading YOLOv8n pretrained model...")
    model = YOLO("yolov8n.pt")
    
    # Get the absolute path to the dataset config
    script_dir = Path(__file__).parent
    dataset_config = script_dir / "experiments" / "configs" / "datasets" / "hripcb_data.yaml"
    
    if not dataset_config.exists():
        raise FileNotFoundError(f"Dataset config not found: {dataset_config}")
    
    print(f"üìÅ Dataset config: {dataset_config}")
    
    # Research-validated hyperparameters for HRIPCB
    training_config = {
        # Dataset configuration
        'data': str(dataset_config),
        
        # Training duration - research shows 150 epochs optimal for HRIPCB
        'epochs': 150,
        'patience': 50,  # Higher patience for stable convergence
        
        # Image and batch settings
        'imgsz': 640,
        'batch': 64,     # Increased to utilize full 15GB GPU memory
        
        # Optimizer settings - SGD proven optimal for small defect detection
        'optimizer': 'SGD',
        'lr0': 0.01,           # Research-validated initial learning rate
        'lrf': 0.01,           # Final learning rate factor
        'momentum': 0.937,
        'weight_decay': 0.0005,
        
        # Learning rate scheduler
        'warmup_epochs': 3.0,
        'warmup_momentum': 0.8,
        'warmup_bias_lr': 0.1,
        
        # Loss weights (standard for class-balanced dataset)
        'box': 7.5,      # Box regression loss weight  
        'cls': 0.5,      # Classification loss weight (BCE - optimal for balanced data)
        'dfl': 1.5,      # Distribution focal loss weight
        
        # Data augmentation - reduced mosaic for small defects
        'mosaic': 0.8,   # Research shows 0.8 better than default 1.0 for linear defects
        'mixup': 0.0,    # Disabled - can hurt small defect detection
        'copy_paste': 0.0,  # Disabled for PCB defects
        
        # Color augmentation (minimal for industrial images)
        'hsv_h': 0.015,  # Hue
        'hsv_s': 0.7,    # Saturation  
        'hsv_v': 0.4,    # Value
        
        # Geometric augmentation
        'degrees': 0.0,     # No rotation for PCB boards
        'translate': 0.1,   # Minimal translation
        'scale': 0.5,       # Scale variation
        'shear': 0.0,       # No shearing for PCB
        'perspective': 0.0, # No perspective for flat PCBs
        'flipud': 0.0,      # No vertical flip
        'fliplr': 0.5,      # Horizontal flip OK for PCBs
        
        # Training settings
        'save': True,
        'save_period': 10,  # Save checkpoint every 10 epochs
        'cache': True,      # Enabled for faster data loading
        'device': '0',      # GPU device
        'workers': 16,      # Increased data loading workers
        'project': 'runs/train',
        'name': f'yolov8n_hripcb_{loss_function}_loss_optimized',
        'exist_ok': True,
        'pretrained': True,
        'verbose': True,
        
        # Advanced settings
        'amp': True,        # Automatic Mixed Precision
        'fraction': 1.0,    # Use full dataset
        'profile': False,   # Disable profiling for speed
        'freeze': None,     # No layer freezing needed
        'multi_scale': False,  # Disable for consistent small defects
        'overlap_mask': True,
        'mask_ratio': 4,
        'dropout': 0.0,     # No dropout needed for balanced dataset
        'val': True,        # Enable validation
        'split': 'val',     # Validation split
    }
    
    print("üöÄ Starting optimized training...")
    print("‚è≥ Training will take approximately 2-4 hours depending on hardware")
    print("\nüìã Key optimizations for HRIPCB:")
    print("   ‚Ä¢ SIoU/EIoU loss for linear defects")
    print("   ‚Ä¢ SGD optimizer with lr0=0.01")  
    print("   ‚Ä¢ Reduced mosaic=0.8 for small defects")
    print("   ‚Ä¢ 150 epochs with patience=50")
    print("   ‚Ä¢ Standard BCE classification (balanced dataset)")
    print()
    
    try:
        # Execute training
        results = model.train(**training_config)
        
        # Training completion
        print("\n" + "=" * 60)
        print("‚úÖ TRAINING COMPLETED SUCCESSFULLY!")
        print("=" * 60)
        print(f"üìä Results saved to: {results.save_dir}")
        print(f"üìà Best mAP@0.5: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}")
        print(f"üìà Best mAP@0.5-0.95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}")
        
        # Model paths
        best_model = results.save_dir / 'weights' / 'best.pt'
        last_model = results.save_dir / 'weights' / 'last.pt'
        
        print("\nüì¶ Model files:")
        print(f"   üèÜ Best: {best_model}")
        print(f"   üìÑ Last: {last_model}")
        
        # Validation recommendation
        print("\nüîç Next steps:")
        print("   1. Validate model on test set")
        print("   2. Switch loss function in loss.py for ablation study")
        print("   3. Compare SIoU vs EIoU performance")
        print("=" * 60)
        
        return results
        
    except Exception as e:
        print(f"\n‚ùå Training failed: {e}")
        print("\nüí° Troubleshooting:")
        print("   ‚Ä¢ Check dataset path in hripcb_data.yaml")
        print("   ‚Ä¢ Ensure CUDA GPU available")
        print("   ‚Ä¢ Reduce batch size if out of memory")
        print("   ‚Ä¢ Verify loss.py modifications are correct")
        return None

def main():
    """Main execution function."""
    
    
    # Execute training with loss function name
    # Change this to "siou", "eiou", or "ciou" based on your loss.py modification
    results = train_hripcb_optimized(loss_function="siou")
    
    if results:
        print("üéâ Training completed! Ready for ablation study.")
    else:
        print("‚ùå Training failed. Check error messages above.")

if __name__ == "__main__":
    main()