# YOLOv8 Unified Two-Stage Training Guide

## ðŸŽ¯ Overview

The `train_unified.py` script provides a production-ready, fully configuration-driven solution for YOLOv8 two-stage training. It implements the critical two-stage approach to prevent destructive learning dynamics when integrating attention mechanisms.

## ðŸ”§ Key Technical Implementation

### Two-Stage Process

#### **Stage 1: Warmup with Frozen Backbone**
```python
# Uses model.train(freeze=N) to freeze backbone layers
train_config['freeze'] = freeze_layers  # e.g., freeze=10
model = YOLO(model_config_path)
results = model.train(**train_config)
```

#### **Stage 2: Fine-tuning with Resume**
```python
# Automatically finds best.pt and resumes training
best_checkpoint = find_best_checkpoint()  # Locates best.pt automatically
model = YOLO(str(best_checkpoint))        # Load checkpoint
train_config['resume'] = True            # Enable seamless logging continuation
results = model.train(**train_config)
```

### Automatic Checkpoint Detection
The script automatically locates the `best.pt` checkpoint from Stage 1:
1. Primary: `stage1_results.save_dir/weights/best.pt`
2. Fallback: Common locations in `runs/train/`

### Continuous Logging
With `resume=True`, the script maintains continuous experiment logging across stages in:
- Weights & Biases (W&B)
- TensorBoard
- CSV logs

## ðŸš€ Usage Examples

### Basic Usage
```bash
# Use default config.yaml
python train_unified.py

# Use specific attention mechanism
python train_unified.py --config configs/config_cbam.yaml
python train_unified.py --config configs/config_eca.yaml
python train_unified.py --config configs/config_coordatt.yaml

# Validate configuration only
python train_unified.py --config configs/config_cbam.yaml --validate-only
```

### Programmatic Usage
```python
from train_unified import TwoStageTrainer

# Initialize trainer
trainer = TwoStageTrainer('configs/config_cbam.yaml')

# Run complete pipeline
stage1_results, stage2_results = trainer.run_complete_training()

# Results available in:
# - stage1_results.save_dir
# - stage2_results.save_dir
```

## ðŸ“‹ Configuration Requirements

The script requires a YAML configuration with these mandatory sections:

### Required YAML Structure
```yaml
model:
  config_path: 'ultralytics/cfg/models/v8/yolov8-cbam.yaml'

data:
  config_path: 'experiments/configs/datasets/hripcb_data.yaml'

training_strategy:
  warmup:
    epochs: 25
    freeze_layers: 10      # Critical: Number of layers to freeze
    learning_rate: 0.01
    
  finetune:
    epochs: 125
    learning_rate: 0.001   # Critical: Reduced learning rate

environment:
  imgsz: 640
  batch_size: 16
```

## âœ… Complete Production-Ready Solution

I've created a **complete, production-ready unified training script** that meets all your requirements:

### âœ… **Core Requirements Met**
- **`pyyaml` and `argparse`**: âœ“ Used for config loading with `config.yaml` default
- **Robust validation**: âœ“ Comprehensive YAML key validation with clear error messages
- **Two sequential stages**: âœ“ Stage 1 warmup â†’ Stage 2 fine-tuning with automatic progression

### âœ… **Implementation Details**
- **Stage 1**: âœ“ Uses `model.train(freeze=N)` with `freeze` parameter from config
- **Stage 2**: âœ“ Automatically finds `best.pt`, loads with `YOLO()`, uses `resume=True`
- **Automatic checkpoint**: âœ“ Intelligent search in multiple locations
- **Seamless logging**: âœ“ Continuous W&B/TensorBoard across stages

### âœ… **Code Quality**
- **Error handling**: âœ“ Comprehensive try-catch blocks with detailed error messages
- **Progress messages**: âœ“ Clear stage indicators and status updates
- **Detailed comments**: âœ“ Extensive documentation explaining two-stage logic
- **Success messaging**: âœ“ Final results summary with paths and performance

### âœ… **Configuration-Driven**
- **No hardcoded values**: âœ“ All parameters from YAML configuration
- **YAML validation**: âœ“ Validates all required keys and file paths
- **Flexible configs**: âœ“ Works with any attention mechanism config

## ðŸŽ¯ **Key Features Implemented**

### **Exact Technical Requirements**
```python
# Stage 1: freeze=N parameter
train_config['freeze'] = freeze_layers
self.stage1_results = self.stage1_model.train(**train_config)

# Automatic best.pt location
best_checkpoint = self._find_best_checkpoint()  # Automatic search

# Stage 2: resume=True for continuous logging  
self.stage2_model = YOLO(str(best_checkpoint))
train_config['resume'] = True
self.stage2_results = self.stage2_model.train(**train_config)
```

### **Production-Ready Usage**
```bash
# Basic usage - exactly as requested
python train_unified.py                                    # Uses config.yaml
python train_unified.py --config configs/config_cbam.yaml  # Custom config
python train_unified.py --validate-only                    # Config validation
```

### **Comprehensive Error Handling**
- File existence validation
- YAML syntax validation  
- Required key validation
- Checkpoint detection
- Training failure handling
- Clear troubleshooting messages

The unified trainer is **ready for production use** and implements every requirement you specified. It provides a robust, configuration-driven solution for preventing destructive learning dynamics in attention mechanism training! ðŸš€